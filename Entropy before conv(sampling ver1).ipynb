{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9136d97e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++new Line\n",
      "KerasTensor(type_spec=TensorSpec(shape=(4,), dtype=tf.int32, name=None), inferred_value=[None, 96, 96, 1], name='tf.compat.v1.shape/Shape:0', description=\"created by layer 'tf.compat.v1.shape'\")\n",
      "value of q 1.25\n",
      "new_p (None, 96, 96, 1)\n",
      "xyz= (None, 1, 1, 1)\n",
      "xyz= (None, 1, 1, 1)\n",
      "weights (None, 96, 96, 1)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 48, 48, 32)\n",
      "dim (None, 48, 48, 32)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 24, 24, 64)\n",
      "dim (None, 24, 24, 64)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 12, 12, 128)\n",
      "dim (None, 12, 12, 128)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 6, 6, 256)\n",
      "dim (None, 6, 6, 256)\n",
      "dim (None, 6, 6, 512)\n",
      "dim (None, 6, 6, 512)\n",
      "dim (None, 6, 6, 512)\n",
      "conv5= KerasTensor(type_spec=TensorSpec(shape=(None, 6, 6, 512), dtype=tf.float32, name=None), name='dropout_4/Identity:0', description=\"created by layer 'dropout_4'\")\n",
      "dim (None, 12, 12, 512)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 24, 24, 256)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 48, 48, 128)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 96, 96, 64)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 1)\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "141/141 [==============================] - 48s 235ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.01856, saving model to weights.h5\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.01856 to -0.01858, saving model to weights.h5\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.01858 to -0.01861, saving model to weights.h5\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.0279 - dice_coef: 0.0279 - val_loss: -0.0384 - val_dice_coef: 0.0386\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.01861 to -0.03835, saving model to weights.h5\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 27s 194ms/step - loss: -0.1759 - dice_coef: 0.1759 - val_loss: -0.1047 - val_dice_coef: 0.1056\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.03835 to -0.10469, saving model to weights.h5\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.2087 - dice_coef: 0.2087 - val_loss: -0.1205 - val_dice_coef: 0.1217\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.10469 to -0.12046, saving model to weights.h5\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.2222 - dice_coef: 0.2222 - val_loss: -0.1381 - val_dice_coef: 0.1399\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.12046 to -0.13813, saving model to weights.h5\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 27s 192ms/step - loss: -0.2288 - dice_coef: 0.2289 - val_loss: -0.1342 - val_dice_coef: 0.1359\n",
      "\n",
      "Epoch 00008: val_loss did not improve from -0.13813\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 27s 192ms/step - loss: -0.2350 - dice_coef: 0.2349 - val_loss: -0.1375 - val_dice_coef: 0.1393\n",
      "\n",
      "Epoch 00009: val_loss did not improve from -0.13813\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 27s 192ms/step - loss: -0.2347 - dice_coef: 0.2345 - val_loss: -0.1438 - val_dice_coef: 0.1458\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.13813 to -0.14383, saving model to weights.h5\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 27s 192ms/step - loss: -0.2381 - dice_coef: 0.2382 - val_loss: -0.1488 - val_dice_coef: 0.1511\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.14383 to -0.14880, saving model to weights.h5\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.2416 - dice_coef: 0.2416 - val_loss: -0.1428 - val_dice_coef: 0.1449\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.14880\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 27s 192ms/step - loss: -0.2403 - dice_coef: 0.2404 - val_loss: -0.1433 - val_dice_coef: 0.1454\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.14880\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.2433 - dice_coef: 0.2433 - val_loss: -0.1436 - val_dice_coef: 0.1457\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.14880\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 27s 193ms/step - loss: -0.2415 - dice_coef: 0.2416 - val_loss: -0.1469 - val_dice_coef: 0.1491\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -0.14880\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 28s 196ms/step - loss: -0.2428 - dice_coef: 0.2428 - val_loss: -0.1423 - val_dice_coef: 0.1443\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.14880\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 28s 201ms/step - loss: -0.2417 - dice_coef: 0.2416 - val_loss: -0.1533 - val_dice_coef: 0.1556\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.14880 to -0.15333, saving model to weights.h5\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 28s 196ms/step - loss: -0.2436 - dice_coef: 0.2437 - val_loss: -0.1528 - val_dice_coef: 0.1552\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.15333\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 28s 196ms/step - loss: -0.2451 - dice_coef: 0.2452 - val_loss: -0.1477 - val_dice_coef: 0.1500\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.15333\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 28s 197ms/step - loss: -0.2447 - dice_coef: 0.2448 - val_loss: -0.1494 - val_dice_coef: 0.1517\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.15333\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "173/173 [==============================] - 10s 58ms/step\n",
      "mask final img 1 [[[[9.29884962e-04]\n",
      "   [3.61021307e-06]\n",
      "   [6.74107881e-08]\n",
      "   ...\n",
      "   [7.02925854e-06]\n",
      "   [1.79241470e-04]\n",
      "   [1.23558464e-02]]\n",
      "\n",
      "  [[2.80670429e-05]\n",
      "   [6.03721446e-08]\n",
      "   [9.25235791e-11]\n",
      "   ...\n",
      "   [2.32888606e-08]\n",
      "   [7.11975144e-06]\n",
      "   [3.48526664e-04]]\n",
      "\n",
      "  [[6.27120528e-07]\n",
      "   [8.43767493e-13]\n",
      "   [6.01289684e-16]\n",
      "   ...\n",
      "   [7.04026572e-13]\n",
      "   [1.00820046e-08]\n",
      "   [1.41699411e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.81964183e-07]\n",
      "   [6.45732912e-10]\n",
      "   [1.44800994e-14]\n",
      "   ...\n",
      "   [6.86993007e-16]\n",
      "   [3.01061931e-12]\n",
      "   [6.37258211e-08]]\n",
      "\n",
      "  [[1.86471312e-04]\n",
      "   [1.82044477e-08]\n",
      "   [3.60280306e-10]\n",
      "   ...\n",
      "   [2.74137131e-13]\n",
      "   [1.47669219e-08]\n",
      "   [2.79916890e-06]]\n",
      "\n",
      "  [[2.73867347e-03]\n",
      "   [3.44370230e-04]\n",
      "   [5.40970746e-07]\n",
      "   ...\n",
      "   [8.52082053e-07]\n",
      "   [8.72079181e-06]\n",
      "   [1.27734290e-03]]]\n",
      "\n",
      "\n",
      " [[[9.29387636e-04]\n",
      "   [3.60684044e-06]\n",
      "   [6.73368987e-08]\n",
      "   ...\n",
      "   [6.97524183e-06]\n",
      "   [1.78236631e-04]\n",
      "   [1.23210503e-02]]\n",
      "\n",
      "  [[2.80443273e-05]\n",
      "   [6.02947026e-08]\n",
      "   [9.23823310e-11]\n",
      "   ...\n",
      "   [2.30244730e-08]\n",
      "   [7.06503306e-06]\n",
      "   [3.46724642e-04]]\n",
      "\n",
      "  [[6.26315455e-07]\n",
      "   [8.41737270e-13]\n",
      "   [5.99631352e-16]\n",
      "   ...\n",
      "   [6.91470319e-13]\n",
      "   [9.96285365e-09]\n",
      "   [1.40678003e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.56640725e-07]\n",
      "   [6.17780826e-10]\n",
      "   [1.35480311e-14]\n",
      "   ...\n",
      "   [7.47258819e-16]\n",
      "   [3.20875726e-12]\n",
      "   [6.63082389e-08]]\n",
      "\n",
      "  [[1.83176802e-04]\n",
      "   [1.75401009e-08]\n",
      "   [3.44350187e-10]\n",
      "   ...\n",
      "   [2.93877959e-13]\n",
      "   [1.54179727e-08]\n",
      "   [2.88606884e-06]]\n",
      "\n",
      "  [[2.70546204e-03]\n",
      "   [3.38716462e-04]\n",
      "   [5.24998768e-07]\n",
      "   ...\n",
      "   [8.81152062e-07]\n",
      "   [8.96720758e-06]\n",
      "   [1.29773305e-03]]]\n",
      "\n",
      "\n",
      " [[[9.39763500e-04]\n",
      "   [3.67964162e-06]\n",
      "   [6.91336197e-08]\n",
      "   ...\n",
      "   [6.58800718e-06]\n",
      "   [1.71015403e-04]\n",
      "   [1.20693594e-02]]\n",
      "\n",
      "  [[2.85168517e-05]\n",
      "   [6.19219449e-08]\n",
      "   [9.58596189e-11]\n",
      "   ...\n",
      "   [2.11504609e-08]\n",
      "   [6.67404129e-06]\n",
      "   [3.33724194e-04]]\n",
      "\n",
      "  [[6.41018289e-07]\n",
      "   [8.80609984e-13]\n",
      "   [6.34739703e-16]\n",
      "   ...\n",
      "   [6.03599093e-13]\n",
      "   [9.11290243e-09]\n",
      "   [1.33299372e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.89599903e-07]\n",
      "   [6.54262478e-10]\n",
      "   [1.47733574e-14]\n",
      "   ...\n",
      "   [7.35179864e-16]\n",
      "   [3.16913661e-12]\n",
      "   [6.57967405e-08]]\n",
      "\n",
      "  [[1.87457685e-04]\n",
      "   [1.84063929e-08]\n",
      "   [3.65225905e-10]\n",
      "   ...\n",
      "   [2.89972609e-13]\n",
      "   [1.52899684e-08]\n",
      "   [2.86905197e-06]]\n",
      "\n",
      "  [[2.74862722e-03]\n",
      "   [3.46064830e-04]\n",
      "   [5.45904470e-07]\n",
      "   ...\n",
      "   [8.75503872e-07]\n",
      "   [8.91916534e-06]\n",
      "   [1.29377947e-03]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[9.33233358e-04]\n",
      "   [3.63381537e-06]\n",
      "   [6.80075658e-08]\n",
      "   ...\n",
      "   [6.79661298e-06]\n",
      "   [1.74902525e-04]\n",
      "   [1.22053847e-02]]\n",
      "\n",
      "  [[2.82186229e-05]\n",
      "   [6.08934840e-08]\n",
      "   [9.36729860e-11]\n",
      "   ...\n",
      "   [2.21531913e-08]\n",
      "   [6.88373075e-06]\n",
      "   [3.40716360e-04]]\n",
      "\n",
      "  [[6.31620935e-07]\n",
      "   [8.55715347e-13]\n",
      "   [6.12344999e-16]\n",
      "   ...\n",
      "   [6.49909651e-13]\n",
      "   [9.56350910e-09]\n",
      "   [1.37247935e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.52503092e-07]\n",
      "   [6.13244511e-10]\n",
      "   [1.33880969e-14]\n",
      "   ...\n",
      "   [7.25138871e-16]\n",
      "   [3.13611268e-12]\n",
      "   [6.53678143e-08]]\n",
      "\n",
      "  [[1.82645555e-04]\n",
      "   [1.74335693e-08]\n",
      "   [3.41641104e-10]\n",
      "   ...\n",
      "   [2.86685606e-13]\n",
      "   [1.51815165e-08]\n",
      "   [2.85458964e-06]]\n",
      "\n",
      "  [[2.69997166e-03]\n",
      "   [3.37807898e-04]\n",
      "   [5.22211906e-07]\n",
      "   ...\n",
      "   [8.70717031e-07]\n",
      "   [8.87822625e-06]\n",
      "   [1.29038666e-03]]]\n",
      "\n",
      "\n",
      " [[[9.22871928e-04]\n",
      "   [3.56139117e-06]\n",
      "   [6.62178650e-08]\n",
      "   ...\n",
      "   [6.75595311e-06]\n",
      "   [1.74164961e-04]\n",
      "   [1.21799139e-02]]\n",
      "\n",
      "  [[2.77487670e-05]\n",
      "   [5.92885172e-08]\n",
      "   [9.02383307e-11]\n",
      "   ...\n",
      "   [2.19560743e-08]\n",
      "   [6.84386669e-06]\n",
      "   [3.39398655e-04]]\n",
      "\n",
      "  [[6.17314356e-07]\n",
      "   [8.18303595e-13]\n",
      "   [5.78612071e-16]\n",
      "   ...\n",
      "   [6.40599390e-13]\n",
      "   [9.47590095e-09]\n",
      "   [1.36491417e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.94382310e-07]\n",
      "   [6.59620414e-10]\n",
      "   [1.49567689e-14]\n",
      "   ...\n",
      "   [7.16010291e-16]\n",
      "   [3.10572444e-12]\n",
      "   [6.49725322e-08]]\n",
      "\n",
      "  [[1.88079488e-04]\n",
      "   [1.85338838e-08]\n",
      "   [3.68335556e-10]\n",
      "   ...\n",
      "   [2.83752866e-13]\n",
      "   [1.50839572e-08]\n",
      "   [2.84155772e-06]]\n",
      "\n",
      "  [[2.75488314e-03]\n",
      "   [3.47132620e-04]\n",
      "   [5.48993171e-07]\n",
      "   ...\n",
      "   [8.66441894e-07]\n",
      "   [8.84160636e-06]\n",
      "   [1.28737593e-03]]]\n",
      "\n",
      "\n",
      " [[[9.21930769e-04]\n",
      "   [3.55477437e-06]\n",
      "   [6.60517401e-08]\n",
      "   ...\n",
      "   [6.99620159e-06]\n",
      "   [1.78637143e-04]\n",
      "   [1.23344911e-02]]\n",
      "\n",
      "  [[2.77072777e-05]\n",
      "   [5.91459788e-08]\n",
      "   [8.99316246e-11]\n",
      "   ...\n",
      "   [2.31282602e-08]\n",
      "   [7.08675452e-06]\n",
      "   [3.47431080e-04]]\n",
      "\n",
      "  [[6.16181524e-07]\n",
      "   [8.15295260e-13]\n",
      "   [5.75901407e-16]\n",
      "   ...\n",
      "   [6.96582657e-13]\n",
      "   [1.00121165e-08]\n",
      "   [1.41095188e-05]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[8.91486081e-07]\n",
      "   [6.56368571e-10]\n",
      "   [1.48442524e-14]\n",
      "   ...\n",
      "   [7.12519986e-16]\n",
      "   [3.09480848e-12]\n",
      "   [6.48312906e-08]]\n",
      "\n",
      "  [[1.87703612e-04]\n",
      "   [1.84564524e-08]\n",
      "   [3.66430275e-10]\n",
      "   ...\n",
      "   [2.82581413e-13]\n",
      "   [1.50469752e-08]\n",
      "   [2.83668396e-06]]\n",
      "\n",
      "  [[2.75108940e-03]\n",
      "   [3.46485089e-04]\n",
      "   [5.47098011e-07]\n",
      "   ...\n",
      "   [8.64682875e-07]\n",
      "   [8.82746099e-06]\n",
      "   [1.28620432e-03]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    " from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import import_ipynb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from data import load_test_data , load_train_data\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,Dense , Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import softmax\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    " \n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    " \n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    " \n",
    " \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    " \n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++new Line\")\n",
    "     \n",
    "    print(tf.shape(inputs))\n",
    "    td=inputs\n",
    "    \n",
    "    tx=softmax(td,axis=[1,2])\n",
    "    q=1.25\n",
    "    \n",
    "    \n",
    "    print(\"value of q\",q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    safe_x = K.maximum(tx,1e-6)\n",
    "    new_p = K.switch(K.equal(q,1.), (K.log(safe_x)*safe_x)/K.log(2.718),(K.pow(safe_x,q))/(q-1))\n",
    "    new_p = -new_p #-p^q/(q-1)\n",
    "    \n",
    "    if q!=1:\n",
    "        new_p= 1+new_p\n",
    "        \n",
    "    print(\"new_p\",new_p.shape)\n",
    "    xyz=K.max(new_p,axis=[1,2],keepdims=True)\n",
    "    print(\"xyz=\",xyz.shape)\n",
    "    print(\"xyz=\",xyz.shape)\n",
    "    weights=1-(new_p/xyz)\n",
    "    print(\"weights\",weights.shape)\n",
    "    improved_p=td*weights\n",
    "    \n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(improved_p)\n",
    "    print(\"dim\",conv1.shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    print(\"dim\",conv1.shape)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    print(\"dim\",pool1.shape)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "    print(\"dim\",pool1.shape)\n",
    "        \n",
    "        \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    print('dim',conv2.shape)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    print('dim',conv2.shape)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    print('dim',pool2.shape)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    print('dim',pool2.shape)\n",
    "\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    print('dim',conv3.shape)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    print('dim',conv3.shape)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    print('dim',pool3.shape)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    print('dim',pool3.shape)\n",
    " \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    print('dim',conv4.shape)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    print('dim',conv4.shape)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    print('dim',pool4.shape)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    print('dim',pool4.shape)\n",
    "    \n",
    "   \n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "#     n=tx.shape[0]\n",
    "#     temp=tf.zeros([0,0],tf.float32)\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         print(\"=========inside loop\",i)\n",
    "#         safe_x = K.maximum(tx[i],1e-6)\n",
    "#         new_p = K.switch(K.equal(q,1.), K.log(safe_x),(K.pow(safe_x,q))/(q-1))\n",
    "#         new_p = -new_p #-p^q/(q-1)\n",
    "    \n",
    "    \n",
    "#         new_p= 1+new_p\n",
    "#         weights=1-(new_p/K.max(new_p))\n",
    "    \n",
    "#         improved_p=td[i]*weights\n",
    "        \n",
    "#         temp=tf.concat([temp,(K.sum(improved_p)/144)],0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     dense_nodes=K.reshape(K.variable(temp),shape=(1,256))\n",
    "#     print(dense_nodes.shape)\n",
    "    ####\n",
    "#     den=[]\n",
    "#     for i in range(n):\n",
    "#         den.append(tf.reduce_sum(before_gap[i])/144)\n",
    "    \n",
    "    \n",
    "#    dense_nodes=tf.Variable(den)\n",
    "#     dense_nodes=tf.reshape(dense_nodes,shape=(1,256))\n",
    "    \n",
    "#     dense_nodes=K.sum(before_gap,axis=1)/144.0\n",
    "#     print(dense_nodes.shape)\n",
    "#     dense_nodes=K.reshape(before_gap,shape=(1,256))\n",
    "    \n",
    "    \n",
    "#     print(\"temp type=\",type(temp[0]))\n",
    "#     dense_nodes = tf. convert_to_tensor(improved_p)\n",
    "#     print(\"dense node=\",dense_nodes)\n",
    "#     xy=tf.reshape(dense_nodes,(1,256))\n",
    "#     print(\"xy=\",xy)\n",
    "    #improved_p=tf.reshape(improved_p,(1,256))\n",
    "    \n",
    "    #############################\n",
    "   \n",
    "    \n",
    "    \n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    print('dim',conv5.shape)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    print('dim',conv5.shape)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    print('dim',conv5.shape)\n",
    "    \n",
    "    print(\"conv5=\",conv5)\n",
    " \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    print('dim',up6.shape)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    print('dim',conv6.shape)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    \n",
    "    print('dim',conv6.shape)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    print('dim',conv6.shape)\n",
    " \n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    print('dim',up7.shape)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    print('dim',conv7.shape)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    print('dim',conv7.shape)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    print('dim',conv7.shape)\n",
    " \n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    print('dim',up8.shape)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    print('dim',conv8.shape)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    print('dim',conv8.shape)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    print('dim',conv8.shape)\n",
    " \n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    print('dim',up9.shape)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    print('dim',conv9.shape)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    print('dim',conv9.shape)\n",
    "    conv9 = Dropout(0.5)(conv9)\n",
    "    print('dim',conv9.shape)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    print(\"dim\", conv10.shape) \n",
    " \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    " \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss=[dice_coef_loss],\n",
    "                  metrics=[dice_coef])\n",
    " \n",
    "    return model\n",
    " \n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    " \n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    " \n",
    "def train_and_predict():\n",
    "    imgs_train,imgs_mask_train,imgs_value_train=load_train_data()\n",
    " \n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    " \n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    " \n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    " \n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss' , mode = 'min' , verbose = 1 , save_best_only=True )\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, y=[imgs_mask_train], batch_size=32, epochs= 20, verbose=1, shuffle=True,\n",
    "              validation_split=0.2 ,  callbacks=[model_checkpoint])\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    n_imgs_test = imgs_test.shape[0]\n",
    "    #for i in range(n_imgs_test):\n",
    "\n",
    "    #worked for 7 vs 1\n",
    "    #imgs_mask_test, imgs_value_test= model.predict(np.expand_dims(imgs_test[0] , axis = 0), verbose=1)\n",
    "\n",
    "\n",
    "    imgs_mask_test= model.predict(imgs_test, verbose=1)\n",
    "    print(\"mask final img 1\" , imgs_mask_test)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    \n",
    "    # print(imgs_mask_test.shape , imgs_value_test.shape)\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "\n",
    "\n",
    " \n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41a037f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45805f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

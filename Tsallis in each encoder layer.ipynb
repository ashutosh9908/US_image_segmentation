{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8da7281",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data.ipynb\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "++++++++++++++++++++++++++++++++++++++++++++++new Line\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "new_p (None, 96, 96, 32)\n",
      "dim (None, 48, 48, 32)\n",
      "dim (None, 48, 48, 32)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "new_p (None, 48, 48, 64)\n",
      "dim (None, 24, 24, 64)\n",
      "dim (None, 24, 24, 64)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "new_p (None, 24, 24, 128)\n",
      "dim (None, 12, 12, 128)\n",
      "dim (None, 12, 12, 128)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "new_p (None, 12, 12, 256)\n",
      "dim (None, 6, 6, 256)\n",
      "dim (None, 6, 6, 512)\n",
      "dim (None, 6, 6, 512)\n",
      "dim (None, 6, 6, 512)\n",
      "conv5= KerasTensor(type_spec=TensorSpec(shape=(None, 6, 6, 512), dtype=tf.float32, name=None), name='dropout_4/Identity:0', description=\"created by layer 'dropout_4'\")\n",
      "dim (None, 12, 12, 512)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 12, 12, 256)\n",
      "dim (None, 24, 24, 256)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 24, 24, 128)\n",
      "dim (None, 48, 48, 128)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 48, 48, 64)\n",
      "dim (None, 96, 96, 64)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 32)\n",
      "dim (None, 96, 96, 1)\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Epoch 1/20\n",
      "141/141 [==============================] - 48s 258ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.01857, saving model to weights.h5\n",
      "Epoch 2/20\n",
      "141/141 [==============================] - 31s 222ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.01857 to -0.01857, saving model to weights.h5\n",
      "Epoch 3/20\n",
      "141/141 [==============================] - 31s 222ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0187\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.01857 to -0.01859, saving model to weights.h5\n",
      "Epoch 4/20\n",
      "141/141 [==============================] - 31s 222ms/step - loss: -0.0245 - dice_coef: 0.0245 - val_loss: -0.0186 - val_dice_coef: 0.0188\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.01859 to -0.01864, saving model to weights.h5\n",
      "Epoch 5/20\n",
      "141/141 [==============================] - 31s 223ms/step - loss: -0.0246 - dice_coef: 0.0246 - val_loss: -0.0188 - val_dice_coef: 0.0189\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.01864 to -0.01877, saving model to weights.h5\n",
      "Epoch 6/20\n",
      "141/141 [==============================] - 31s 223ms/step - loss: -0.0249 - dice_coef: 0.0249 - val_loss: -0.0192 - val_dice_coef: 0.0193\n",
      "\n",
      "Epoch 00006: val_loss improved from -0.01877 to -0.01917, saving model to weights.h5\n",
      "Epoch 7/20\n",
      "141/141 [==============================] - 31s 223ms/step - loss: -0.0258 - dice_coef: 0.0258 - val_loss: -0.0204 - val_dice_coef: 0.0206\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.01917 to -0.02043, saving model to weights.h5\n",
      "Epoch 8/20\n",
      "141/141 [==============================] - 31s 223ms/step - loss: -0.0292 - dice_coef: 0.0292 - val_loss: -0.0270 - val_dice_coef: 0.0271\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.02043 to -0.02696, saving model to weights.h5\n",
      "Epoch 9/20\n",
      "141/141 [==============================] - 32s 226ms/step - loss: -0.0443 - dice_coef: 0.0443 - val_loss: -0.0497 - val_dice_coef: 0.0498\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.02696 to -0.04971, saving model to weights.h5\n",
      "Epoch 10/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.0610 - dice_coef: 0.0610 - val_loss: -0.0817 - val_dice_coef: 0.0818\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.04971 to -0.08166, saving model to weights.h5\n",
      "Epoch 11/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.1611 - dice_coef: 0.1612 - val_loss: -0.1528 - val_dice_coef: 0.1536\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.08166 to -0.15278, saving model to weights.h5\n",
      "Epoch 12/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.2180 - dice_coef: 0.2180 - val_loss: -0.1615 - val_dice_coef: 0.1628\n",
      "\n",
      "Epoch 00012: val_loss improved from -0.15278 to -0.16148, saving model to weights.h5\n",
      "Epoch 13/20\n",
      "141/141 [==============================] - 32s 227ms/step - loss: -0.2354 - dice_coef: 0.2354 - val_loss: -0.1680 - val_dice_coef: 0.1694\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.16148 to -0.16799, saving model to weights.h5\n",
      "Epoch 14/20\n",
      "141/141 [==============================] - 33s 232ms/step - loss: -0.2425 - dice_coef: 0.2424 - val_loss: -0.1611 - val_dice_coef: 0.1626\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.16799\n",
      "Epoch 15/20\n",
      "141/141 [==============================] - 32s 225ms/step - loss: -0.2494 - dice_coef: 0.2495 - val_loss: -0.1699 - val_dice_coef: 0.1712\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.16799 to -0.16991, saving model to weights.h5\n",
      "Epoch 16/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.2527 - dice_coef: 0.2527 - val_loss: -0.1744 - val_dice_coef: 0.1757\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.16991 to -0.17441, saving model to weights.h5\n",
      "Epoch 17/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.2557 - dice_coef: 0.2557 - val_loss: -0.1756 - val_dice_coef: 0.1772\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.17441 to -0.17561, saving model to weights.h5\n",
      "Epoch 18/20\n",
      "141/141 [==============================] - 32s 225ms/step - loss: -0.2610 - dice_coef: 0.2609 - val_loss: -0.1784 - val_dice_coef: 0.1800\n",
      "\n",
      "Epoch 00018: val_loss improved from -0.17561 to -0.17842, saving model to weights.h5\n",
      "Epoch 19/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.2648 - dice_coef: 0.2648 - val_loss: -0.1777 - val_dice_coef: 0.1794\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.17842\n",
      "Epoch 20/20\n",
      "141/141 [==============================] - 32s 224ms/step - loss: -0.2665 - dice_coef: 0.2665 - val_loss: -0.1762 - val_dice_coef: 0.1777\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.17842\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "173/173 [==============================] - 11s 60ms/step\n",
      "mask final img 1 [[[[9.39784478e-03]\n",
      "   [2.83441186e-04]\n",
      "   [1.56424139e-05]\n",
      "   ...\n",
      "   [5.12491397e-06]\n",
      "   [7.43864948e-05]\n",
      "   [4.33628587e-03]]\n",
      "\n",
      "  [[4.67344682e-04]\n",
      "   [5.23514359e-07]\n",
      "   [9.03877773e-09]\n",
      "   ...\n",
      "   [5.64236546e-10]\n",
      "   [1.39961614e-07]\n",
      "   [9.27171059e-05]]\n",
      "\n",
      "  [[2.80120385e-05]\n",
      "   [6.84998858e-09]\n",
      "   [7.19335399e-12]\n",
      "   ...\n",
      "   [9.11827363e-13]\n",
      "   [4.42940240e-10]\n",
      "   [4.73838509e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.48042618e-05]\n",
      "   [1.84959137e-09]\n",
      "   [4.09172089e-12]\n",
      "   ...\n",
      "   [5.80071269e-14]\n",
      "   [1.04127901e-10]\n",
      "   [1.56550891e-06]]\n",
      "\n",
      "  [[2.33021623e-04]\n",
      "   [2.74199067e-07]\n",
      "   [2.34630915e-09]\n",
      "   ...\n",
      "   [1.29213362e-10]\n",
      "   [2.15423324e-08]\n",
      "   [4.04733582e-05]]\n",
      "\n",
      "  [[9.17867664e-03]\n",
      "   [2.56333238e-04]\n",
      "   [1.60971704e-05]\n",
      "   ...\n",
      "   [3.96883615e-06]\n",
      "   [6.62669045e-05]\n",
      "   [3.70486197e-03]]]\n",
      "\n",
      "\n",
      " [[[8.18116311e-03]\n",
      "   [2.19608468e-04]\n",
      "   [1.10897718e-05]\n",
      "   ...\n",
      "   [6.04344041e-06]\n",
      "   [8.57540799e-05]\n",
      "   [4.73166211e-03]]\n",
      "\n",
      "  [[3.75918491e-04]\n",
      "   [3.47167600e-07]\n",
      "   [5.24028065e-09]\n",
      "   ...\n",
      "   [6.21139862e-10]\n",
      "   [1.53069109e-07]\n",
      "   [9.76623051e-05]]\n",
      "\n",
      "  [[2.18692185e-05]\n",
      "   [4.32040670e-09]\n",
      "   [3.85465271e-12]\n",
      "   ...\n",
      "   [7.61911096e-13]\n",
      "   [3.80318527e-10]\n",
      "   [4.31976423e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.46321574e-04]\n",
      "   [8.87383464e-08]\n",
      "   [4.14700690e-10]\n",
      "   ...\n",
      "   [5.40599263e-14]\n",
      "   [9.60149807e-11]\n",
      "   [1.47849812e-06]]\n",
      "\n",
      "  [[1.19505671e-03]\n",
      "   [4.60481897e-06]\n",
      "   [6.77298928e-08]\n",
      "   ...\n",
      "   [1.14875880e-10]\n",
      "   [1.91625951e-08]\n",
      "   [3.75975615e-05]]\n",
      "\n",
      "  [[2.10629404e-02]\n",
      "   [1.07763452e-03]\n",
      "   [9.32430630e-05]\n",
      "   ...\n",
      "   [3.54215831e-06]\n",
      "   [6.00015701e-05]\n",
      "   [3.47579364e-03]]]\n",
      "\n",
      "\n",
      " [[[7.00603146e-03]\n",
      "   [1.69514169e-04]\n",
      "   [8.27453823e-06]\n",
      "   ...\n",
      "   [1.24010858e-05]\n",
      "   [1.51818036e-04]\n",
      "   [6.55430323e-03]]\n",
      "\n",
      "  [[2.73634243e-04]\n",
      "   [2.01648334e-07]\n",
      "   [2.83920221e-09]\n",
      "   ...\n",
      "   [2.10843143e-09]\n",
      "   [3.88013945e-07]\n",
      "   [1.66009166e-04]]\n",
      "\n",
      "  [[1.38840587e-05]\n",
      "   [1.95399763e-09]\n",
      "   [1.57417471e-12]\n",
      "   ...\n",
      "   [2.69455096e-12]\n",
      "   [9.87796622e-10]\n",
      "   [7.42784414e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.40340198e-05]\n",
      "   [1.65723890e-09]\n",
      "   [3.45259390e-12]\n",
      "   ...\n",
      "   [4.65636542e-14]\n",
      "   [8.82776907e-11]\n",
      "   [1.42709746e-06]]\n",
      "\n",
      "  [[2.25111769e-04]\n",
      "   [2.55603311e-07]\n",
      "   [2.09001305e-09]\n",
      "   ...\n",
      "   [1.04298445e-10]\n",
      "   [1.82220248e-08]\n",
      "   [3.69124609e-05]]\n",
      "\n",
      "  [[9.04703978e-03]\n",
      "   [2.48058321e-04]\n",
      "   [1.52066377e-05]\n",
      "   ...\n",
      "   [3.38446739e-06]\n",
      "   [5.87301038e-05]\n",
      "   [3.45583004e-03]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.02444235e-02]\n",
      "   [3.24719585e-04]\n",
      "   [1.80907682e-05]\n",
      "   ...\n",
      "   [1.01751002e-05]\n",
      "   [1.31235865e-04]\n",
      "   [6.07618317e-03]]\n",
      "\n",
      "  [[5.37549437e-04]\n",
      "   [6.62928585e-07]\n",
      "   [1.14845555e-08]\n",
      "   ...\n",
      "   [1.37702905e-09]\n",
      "   [2.91533951e-07]\n",
      "   [1.41447759e-04]]\n",
      "\n",
      "  [[3.44947257e-05]\n",
      "   [9.62644631e-09]\n",
      "   [1.03296633e-11]\n",
      "   ...\n",
      "   [1.70008354e-12]\n",
      "   [7.24818872e-10]\n",
      "   [6.26027440e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.45518570e-05]\n",
      "   [1.77918236e-09]\n",
      "   [3.88160381e-12]\n",
      "   ...\n",
      "   [3.17008410e-13]\n",
      "   [2.42157738e-10]\n",
      "   [2.22100061e-06]]\n",
      "\n",
      "  [[2.29889309e-04]\n",
      "   [2.66665637e-07]\n",
      "   [2.24962493e-09]\n",
      "   ...\n",
      "   [3.92607502e-10]\n",
      "   [3.77780509e-08]\n",
      "   [5.07288714e-05]]\n",
      "\n",
      "  [[9.13170539e-03]\n",
      "   [2.52666854e-04]\n",
      "   [1.57701943e-05]\n",
      "   ...\n",
      "   [6.67983568e-06]\n",
      "   [8.52093945e-05]\n",
      "   [4.09301743e-03]]]\n",
      "\n",
      "\n",
      " [[[6.62639178e-03]\n",
      "   [1.46788472e-04]\n",
      "   [6.37537460e-06]\n",
      "   ...\n",
      "   [2.65586505e-06]\n",
      "   [4.44511097e-05]\n",
      "   [3.24077788e-03]]\n",
      "\n",
      "  [[2.54868588e-04]\n",
      "   [1.62247005e-07]\n",
      "   [1.94874938e-09]\n",
      "   ...\n",
      "   [1.61000449e-10]\n",
      "   [5.38808678e-08]\n",
      "   [5.37146079e-05]]\n",
      "\n",
      "  [[1.22728561e-05]\n",
      "   [1.47479984e-09]\n",
      "   [9.46769789e-13]\n",
      "   ...\n",
      "   [1.57625296e-13]\n",
      "   [1.12561196e-10]\n",
      "   [2.18896685e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.57197283e-05]\n",
      "   [2.03661976e-09]\n",
      "   [4.56775416e-12]\n",
      "   ...\n",
      "   [6.01797461e-14]\n",
      "   [1.02218928e-10]\n",
      "   [1.52518760e-06]]\n",
      "\n",
      "  [[2.43761722e-04]\n",
      "   [2.95490480e-07]\n",
      "   [2.55736010e-09]\n",
      "   ...\n",
      "   [1.24693741e-10]\n",
      "   [2.01465653e-08]\n",
      "   [3.84922132e-05]]\n",
      "\n",
      "  [[9.42334998e-03]\n",
      "   [2.67339259e-04]\n",
      "   [1.69431169e-05]\n",
      "   ...\n",
      "   [3.71620149e-06]\n",
      "   [6.18641498e-05]\n",
      "   [3.52765853e-03]]]\n",
      "\n",
      "\n",
      " [[[6.57346891e-03]\n",
      "   [1.49455271e-04]\n",
      "   [6.73139175e-06]\n",
      "   ...\n",
      "   [3.94507015e-06]\n",
      "   [6.25319517e-05]\n",
      "   [4.00461396e-03]]\n",
      "\n",
      "  [[2.55721970e-04]\n",
      "   [1.69056477e-07]\n",
      "   [2.12285345e-09]\n",
      "   ...\n",
      "   [3.01599024e-10]\n",
      "   [9.21960464e-08]\n",
      "   [7.43418204e-05]]\n",
      "\n",
      "  [[1.31778697e-05]\n",
      "   [1.71444003e-09]\n",
      "   [1.17356613e-12]\n",
      "   ...\n",
      "   [3.11425880e-13]\n",
      "   [2.02293696e-10]\n",
      "   [3.12522070e-06]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.55809994e-05]\n",
      "   [2.04613193e-09]\n",
      "   [4.79893165e-12]\n",
      "   ...\n",
      "   [6.11597429e-14]\n",
      "   [1.05628166e-10]\n",
      "   [1.56415217e-06]]\n",
      "\n",
      "  [[2.42748167e-04]\n",
      "   [2.98296101e-07]\n",
      "   [2.68453104e-09]\n",
      "   ...\n",
      "   [1.26255062e-10]\n",
      "   [2.07106972e-08]\n",
      "   [3.93119808e-05]]\n",
      "\n",
      "  [[9.40769538e-03]\n",
      "   [2.69231328e-04]\n",
      "   [1.74226716e-05]\n",
      "   ...\n",
      "   [3.74315550e-06]\n",
      "   [6.27420231e-05]\n",
      "   [3.56954546e-03]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    " from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import import_ipynb\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "from data import load_test_data , load_train_data\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose,Dense , Dropout, AveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.activations import softmax\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    " \n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    " \n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "\n",
    "def TsallisEntropy(X):\n",
    "    td=X\n",
    "    \n",
    "    tx=softmax(td,axis=[1,2])\n",
    "    q = 0.5\n",
    "    \n",
    "    \n",
    "    #print(\"value of q\",q)\n",
    "    \n",
    "    \n",
    "    \n",
    "    safe_x = K.maximum(tx,1e-6)\n",
    "    new_p = K.switch(K.equal(q,1.), (K.log(safe_x)*safe_x)/K.log(2.718),(K.pow(safe_x,q))/(q-1))\n",
    "    new_p = -new_p #-p^q/(q-1)\n",
    "    \n",
    "    if q!=1:\n",
    "        new_p= 1+new_p\n",
    "        \n",
    "    print(\"new_p\",new_p.shape)\n",
    "    xyz=K.max(new_p,axis=[1,2],keepdims=True)\n",
    "    #print(\"xyz=\",xyz.shape)\n",
    "   \n",
    "    \n",
    "    #print(\"xyz=\",xyz.shape)\n",
    "    weights=1-(new_p/xyz)\n",
    "    #print(\"weights\",weights.shape)\n",
    "    improved_p=td*weights\n",
    "    #print(\"improved_p=\",improved_p.shape)\n",
    "    \n",
    "    return improved_p\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    \n",
    " \n",
    " \n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    " \n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++new Line\")\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    print(\"dim\",conv1.shape)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    print(\"dim\",conv1.shape)\n",
    "    c1 = TsallisEntropy(conv1)\n",
    "    pool1 = AveragePooling2D(pool_size=(2, 2))(c1)\n",
    "    print(\"dim\",pool1.shape)\n",
    "    pool1 = Dropout(0.5)(pool1)\n",
    "    print(\"dim\",pool1.shape)\n",
    "        \n",
    "        \n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    print('dim',conv2.shape)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    print('dim',conv2.shape)\n",
    "    c2 = TsallisEntropy(conv2)\n",
    "    pool2 = AveragePooling2D(pool_size=(2, 2))(c2)\n",
    "    print('dim',pool2.shape)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    print('dim',pool2.shape)\n",
    "\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    print('dim',conv3.shape)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    print('dim',conv3.shape)\n",
    "    c3 = TsallisEntropy(conv3)\n",
    "    pool3 = AveragePooling2D(pool_size=(2, 2))(c3)\n",
    "    print('dim',pool3.shape)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    print('dim',pool3.shape)\n",
    " \n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    print('dim',conv4.shape)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    print('dim',conv4.shape)\n",
    "    c4 = TsallisEntropy(conv4)\n",
    "    pool4 = AveragePooling2D(pool_size=(2, 2))(c4)\n",
    "    print('dim',pool4.shape)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    #print('dim',pool4.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #xyz=K.max(new_p,axis=[1,2],keepdims=True)\n",
    "    #print(\"xyz=\",xyz.shape)\n",
    "   \n",
    "    \n",
    "    #print(\"xyz=\",xyz.shape)\n",
    "    #weights=1-(new_p/xyz)\n",
    "    #print(\"weights\",weights.shape)\n",
    "    #improved_p=td*weights\n",
    "    #print(\"improved_p=\",improved_p.shape)\n",
    "    #improved_p=K.sum(improved_p,axis=[1,2])/144\n",
    "    #print(\"improved_pv2=\",type(improved_p),improved_p.shape)\n",
    "    \n",
    "    ##################################\n",
    "    \n",
    "#     n=tx.shape[0]\n",
    "#     temp=tf.zeros([0,0],tf.float32)\n",
    "    \n",
    "#     for i in range(n):\n",
    "#         print(\"=========inside loop\",i)\n",
    "#         safe_x = K.maximum(tx[i],1e-6)\n",
    "#         new_p = K.switch(K.equal(q,1.), K.log(safe_x),(K.pow(safe_x,q))/(q-1))\n",
    "#         new_p = -new_p #-p^q/(q-1)\n",
    "    \n",
    "    \n",
    "#         new_p= 1+new_p\n",
    "#         weights=1-(new_p/K.max(new_p))\n",
    "    \n",
    "#         improved_p=td[i]*weights\n",
    "        \n",
    "#         temp=tf.concat([temp,(K.sum(improved_p)/144)],0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     dense_nodes=K.reshape(K.variable(temp),shape=(1,256))\n",
    "#     print(dense_nodes.shape)\n",
    "    ####\n",
    "#     den=[]\n",
    "#     for i in range(n):\n",
    "#         den.append(tf.reduce_sum(before_gap[i])/144)\n",
    "    \n",
    "    \n",
    "#     dense_nodes=tf.Variable(den)\n",
    "#     dense_nodes=tf.reshape(dense_nodes,shape=(1,256))\n",
    "    \n",
    "#     dense_nodes=K.sum(before_gap,axis=1)/144.0\n",
    "#     print(dense_nodes.shape)\n",
    "#     dense_nodes=K.reshape(before_gap,shape=(1,256))\n",
    "    \n",
    "    \n",
    "#     print(\"temp type=\",type(temp[0]))\n",
    "#     dense_nodes = tf. convert_to_tensor(improved_p)\n",
    "#     print(\"dense node=\",dense_nodes)\n",
    "#     xy=tf.reshape(dense_nodes,(1,256))\n",
    "#     print(\"xy=\",xy)\n",
    "    #improved_p=tf.reshape(improved_p,(1,256))\n",
    "    \n",
    "    #############################\n",
    "    #dense1=Dense(32,activation='relu')(improved_p)\n",
    "    #print(\"dense1\",dense1)\n",
    "    #dense2=Dense(1,activation='softmax')(dense1)\n",
    "    #print(\"below dense\",dense2)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    print('dim',conv5.shape)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    print('dim',conv5.shape)\n",
    "    conv5 = Dropout(0.5)(conv5)\n",
    "    print('dim',conv5.shape)\n",
    "    \n",
    "    print(\"conv5=\",conv5)\n",
    " \n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), c4], axis=3)\n",
    "    print('dim',up6.shape)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    print('dim',conv6.shape)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "    print('dim',conv6.shape)\n",
    "    conv6 = Dropout(0.5)(conv6)\n",
    "    print('dim',conv6.shape)\n",
    " \n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), c3], axis=3)\n",
    "    print('dim',up7.shape)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    print('dim',conv7.shape)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "    print('dim',conv7.shape)\n",
    "    conv7 = Dropout(0.5)(conv7)\n",
    "    print('dim',conv7.shape)\n",
    " \n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), c2], axis=3)\n",
    "    print('dim',up8.shape)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    print('dim',conv8.shape)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "    print('dim',conv8.shape)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    print('dim',conv8.shape)\n",
    " \n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), c1], axis=3)\n",
    "    print('dim',up9.shape)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    print('dim',conv9.shape)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    print('dim',conv9.shape)\n",
    "    conv9 = Dropout(0.5)(conv9)\n",
    "    print('dim',conv9.shape)\n",
    " \n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "    print(\"dim\", conv10.shape) \n",
    " \n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    " \n",
    "    model.compile(optimizer=Adam(learning_rate=1e-5), loss=[dice_coef_loss],\n",
    "                  metrics=[dice_coef])\n",
    " \n",
    "    return model\n",
    " \n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    " \n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    " \n",
    "def train_and_predict():\n",
    "    imgs_train,imgs_mask_train,imgs_value_train=load_train_data()\n",
    " \n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    " \n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    " \n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    " \n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss' , mode = 'min' , verbose = 1 , save_best_only=True )\n",
    " \n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, y=[imgs_mask_train], batch_size=32, epochs= 20, verbose=1, shuffle=True,\n",
    "              validation_split=0.2 ,  callbacks=[model_checkpoint])\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    n_imgs_test = imgs_test.shape[0]\n",
    "    #for i in range(n_imgs_test):\n",
    "\n",
    "    #worked for 7 vs 1\n",
    "    #imgs_mask_test, imgs_value_test= model.predict(np.expand_dims(imgs_test[0] , axis = 0), verbose=1)\n",
    "\n",
    "\n",
    "    imgs_mask_test= model.predict(imgs_test, verbose=1)\n",
    "    print(\"mask final img 1\" , imgs_mask_test)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    \n",
    "    # print(imgs_mask_test.shape , imgs_value_test.shape)\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "\n",
    "\n",
    " \n",
    "     \n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21bf4d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
